{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation des données\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"offres_data.csv\", index_col=0)\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A faire dans l'ordre\n",
    "\n",
    "1. Filtrer pour garder Data et Donnée(s) (OfferTitle)\n",
    "2. Supprimer duplicate\n",
    "3. Ajouter OfferLabel\n",
    "3. Ajouter Localisations (Région, ville, département)\n",
    "4. Garder colonnes intéressantes\n",
    "5. Supprimer duplicate\n",
    "6. Changer format date\n",
    "7. Gérer les manquants\n",
    "8. Refiltrer les offres sur OfferLabel (data, données)\n",
    "9. Ajout des colonnes ville, code postal etc\n",
    "\n",
    "\n",
    "# Gestion des valeurs manquantes\n",
    "\n",
    "- NC = Domaine, ContractType, TeleWork, DisplayedSalary, \n",
    "- \"\" = Profile\n",
    "- Anonyme = CompanyName\n",
    "- https://cdn-icons-png.flaticon.com/512/1810/1810755.png = CompanyLogo\n",
    "\n",
    "# Colonnes à garder \n",
    "\n",
    "- Id \n",
    "- PublishDate \n",
    "- Domaine \n",
    "- OfferTitle \n",
    "- OfferLabel (Criterions)\n",
    "\n",
    "- ContractType \n",
    "- isFulltime\n",
    "- Telework\n",
    "- DisplayedSalary\n",
    "\n",
    "- Description # Première partie de l'annonce \n",
    "- Profile # Seconde Partie de l'annonce \n",
    "\n",
    "- CompanyName\n",
    "- CompanyLogo\n",
    "- Localisation (a droper pour Localisations)\n",
    "\n",
    "- UrlOffre\n",
    "\n",
    "# Besoins\n",
    "\n",
    "- DisplayedSalary -> Rajouté colonne salaire Min/Max \n",
    "- Recherche de hor./semaine\n",
    "- Localisations -> Pour chopper le max d'infos : Régions, ville, départements sur 3 colonnes ✅\n",
    "- Recherche NLP des SoftSkills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Filtrer les annonces Data et Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df_filtered = df[df['OfferTitle'].str.contains(r\"(data|donn[eé]e)\", flags=re.IGNORECASE, na=False, regex=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4864, 63)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On passe d'un DF de +21000 à +4800 entrées\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Supprimer duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A refaire plus loin pour vérifier\n",
    "df_filtered.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4863, 63)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On obtient une entrée en moins\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ajouter OfferLabel pour récupérer le type du poste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def eval(text):\n",
    "    # liste = []\n",
    "    ma_liste = ast.literal_eval(text)\n",
    "    return ma_liste[0]['Label']\n",
    "\n",
    "df_filtered['OfferLabel'] = df_filtered['Criterions'].apply(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Garder colonnes intéressantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_filtered[['Id', 'PublishDate', 'Domaine', 'OfferTitle', 'OfferLabel', 'ContractType', 'IsFulltime', 'Telework', 'DisplayedSalary', 'Description', 'Profile', 'CompanyName', 'CompanyLogo', 'Localisations', 'UrlOffre']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Supprimer duplicate (part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2141, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Changer format date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def date_format(date):\n",
    "    #new_date = datetime.strptime(str(date), \"%Y-%m-%d\")\n",
    "    #new_format = date.strftime(date, \"%Y-%m-%dT%H:%M:%S\")\n",
    "    regex = re.findall(r\"T\\d+:\\d+:\\d+.\\d+\", date)\n",
    "    regex = \" \".join(regex)\n",
    "    new_format = date.replace(regex, \"\")\n",
    "    return new_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['PublishDate'] = df_clean['PublishDate'].apply(date_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['PublishDate'] = df_clean['PublishDate'].apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Gérer les valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On remplace les valeurs vides par NC (non communiqué) sur les colonnes sélectionnées\n",
    "df_clean['Domaine'].fillna(\"NC\", inplace=True)\n",
    "df_clean['ContractType'].fillna(\"NC\", inplace=True)\n",
    "df_clean['Telework'].fillna(\"NC\", inplace=True)\n",
    "df_clean['DisplayedSalary'].fillna(\"NC\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On met une chaine vide à la place des NaN\n",
    "df_clean['Profile'].fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les entreprises souhaitant rester anonymes\n",
    "df_clean['CompanyName'].fillna(\"Anonyme\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On met un logo par défaut aux annonces qui n'en ont pas\n",
    "df_clean['CompanyLogo'].fillna(\"https://cdn-icons-png.flaticon.com/512/1810/1810755.png\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Refiltrer les offres sur OfferLabel (data, données)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On refiltre sur OfferLabel pour ne garder que les annonces du type \"data\", \"données\"\n",
    "df_final = df_clean[df_clean['OfferLabel'].str.contains(r\"(data|donn[eé]e)\", flags=re.IGNORECASE, na=False, regex=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ingénieur big data', 'Analyste de données', 'Data manager',\n",
       "       'Consultant en big data', 'Data miner',\n",
       "       'Architecte de bases de données', 'Ingénieur bases de données',\n",
       "       'Architecte big data', 'Data scientist', 'Responsable data LAB',\n",
       "       'Délégué à la protection des données',\n",
       "       'Administrateur de bases de données', 'Technicien de données',\n",
       "       'Ingénieur qualité des données', 'Responsable bases de données',\n",
       "       'Administrateur data center', 'Technicien data center'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Résultat\n",
    "df_final['OfferLabel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['OfferLabel'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1693, 15)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On se retrouve avec un jeu de +1600 entrées\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Ajout des colonnes ville, code postal etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée un df temporaire pour travailler nos données\n",
    "df_loc = df_final[['Id', 'Localisations']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire données de localisation\n",
    "\n",
    "import ast\n",
    "\n",
    "def extract_coordonnees(text, df_loc):\n",
    "\n",
    "    def eval_objet():\n",
    "        ma_liste = []\n",
    "        if isinstance(text, str):\n",
    "            ma_liste = ast.literal_eval(text)\n",
    "            #print(ma_liste)\n",
    "\n",
    "            pays = None\n",
    "            region = []\n",
    "            departement = []\n",
    "            ville = []\n",
    "            codepostal = []\n",
    "\n",
    "            for dico in ma_liste:\n",
    "                if dico['Type'] == 'Pays':\n",
    "                    pays = dico['Label']\n",
    "                if dico['Type'] == 'Region':\n",
    "                    region.append(dico['Label'])\n",
    "                if dico['Type'] == 'Departement':\n",
    "                    departement.append(dico['Label'])\n",
    "                if dico['Type'] == 'Commune':\n",
    "                    ville.append(dico['Label'])\n",
    "                if dico['Type'] == 'Commune':\n",
    "                    codepostal.append(dico['ShortUri'])\n",
    "                \n",
    "\n",
    "            return pays, region, departement, ville, codepostal\n",
    "\n",
    "        return \"NC\", \"NC\", \"NC\", \"NC\", \"NC\"\n",
    "        \n",
    "    return eval_objet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ajoute les colonnes souhaitées\n",
    "df_loc[['Pays', 'Region', 'Departement', 'Ville', 'CodePostal']] = df_loc['Localisations'].apply(lambda x: pd.Series(extract_coordonnees(x, df_loc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On merge ce df temporaire avec le df_final\n",
    "\n",
    "df_final2 = df_final.merge(df_loc, left_on=\"Id\", right_on=\"Id\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On drop les colonnes indésirables (Localisation_x, Localisation_y)\n",
    "\n",
    "df_final2.drop([\"Localisations_x\", \"Localisations_y\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction salaire\n",
    "\n",
    "def salaire(texte):\n",
    "    dico_s = {}\n",
    "\n",
    "    if '€ / heure' in texte or '€ / jour' in texte or 'NC' in texte:\n",
    "        dico_s[\"salaire_max\"] = \"NA\"\n",
    "        dico_s[\"salaire_min\"] = \"NA\"\n",
    "        \n",
    "    else:\n",
    "        if '-' in texte: \n",
    "            min_a = texte.split('-')[0].replace('\\u202f','').replace(',','.').strip()\n",
    "            max_a = texte.split('-')[1].replace('\\u202f',''\"\"'').replace(',','.').replace(' € / an',\"\").strip()\n",
    "            if '€' in max_a:\n",
    "                min =12*float(min_a)\n",
    "                max = float(max_a.replace('€ / mois', '').strip())*12\n",
    "            else :\n",
    "                min =float(min_a)\n",
    "                max = float(max_a)\n",
    "\n",
    "        else : \n",
    "            max_a = texte.split('-')[0].replace('\\u202f','').replace(',','.').strip().replace(' € / an',\"\")\n",
    "            if '€' in max_a:\n",
    "                max = float(max_a.replace('€ / mois', '').strip())*12\n",
    "            else :\n",
    "                max = float(max_a)\n",
    "            min = max\n",
    "        dico_s[\"salaire_max\"] = int(max)\n",
    "        dico_s[\"salaire_min\"] = int(min)\n",
    "\n",
    "    return dico_s\n",
    "\n",
    "\n",
    "\n",
    "df_final2['salaire'] = df_final2['DisplayedSalary'].apply(salaire)\n",
    "\n",
    "df_final2['salaire_min'] = df_final2['salaire'].apply(lambda x : x['salaire_min'])\n",
    "df_final2['salaire_max'] = df_final2['salaire'].apply(lambda x : x['salaire_max'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on supprime la colonne df['salaire'] et on exporte un CSV \n",
    "df_final2.drop(['salaire'], axis=1, inplace=True)\n",
    "\n",
    "df_final2.to_csv('df_final2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
